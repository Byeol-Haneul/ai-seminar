# ALBERT: A Lite BERT for Self-supervised Learning of Language Representations

## Paper

- https://arxiv.org/abs/1909.11942

- 키워드 : Language Model, Language Representation, BERT

- 한줄 소개 : 기존에 널리 쓰이던 Google에서 발표한 Transformer 기반 Language Model인 BERT의 파라미터 수를 줄이고 성능을 유지 및 향상시킨 모델

### References

- 
