# Word2Vec

###### By Gunhee Cho
## Abstract

- 키워드 : _word embedding, word model, word vector, skip-gram, negative sampling, NCE loss_

- 한줄 소개 : word와 관련된 딥러닝 모델(machine translation 등)의 입력으로 사용할 수 있도록, 단어(word)를 그 단어의 의미(feature)가 드러난 vector로 만든다!

## References

- [Deep Learning Seminar Season 1 발표](https://github.com/HYU-AILAB/ai-seminar/tree/master/season_1/05.%20Word2Vec)
- [논문 내용 요약 (blog)](http://nohhj.blogspot.com/2015/08/word-embedding.html) 
- [Word2Vec 개요 (blog)](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/11/embedding/)
- [학습 방법 (blog)](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/)
- [이론 정리 (blog)](https://shuuki4.wordpress.com/2016/01/27/word2vec-%EA%B4%80%EB%A0%A8-%EC%9D%B4%EB%A1%A0-%EC%A0%95%EB%A6%AC/)
- [활용 (blog)](https://ratsgo.github.io/natural%20language%20processing/2017/03/08/word2vec/)
- [Tensorflow Korea 튜토리얼](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/tutorials/word2vec/)