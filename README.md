# Deep Learning Seminar (Nov 8, 2017 - )
[한양대학교 인공지능연구실](http://ai.hanyang.ac.kr/)에서 매주 진행하는 Deep Learning Seminar 발표 자료 및 구현 코드를 담고 있습니다.

## Seminar Rules
* 주 1회, 일과 후 저녁시간.
* 1명씩 돌아가면서 강의 or 2명이 팀으로 강의.
* 발표자가 발표 관련 자료를 1주일 전에 미리 배포하고, 수강자는 내용을 미리 파악하고 스터디 참석.
* 모든 멤버가 발표를 한 번씩 하면, 한 시즌 끝. 이후 새로 멤버 모집.
* 시즌 도중 탈퇴 시, 벌금 00만원.
* 발표 자료 및 코드는 Github을 통해서 공유 (추후 개인적으로 포트폴리오 활용 가능하도록).

## Members
* 이주홍
* 조건희
* 권명하
* 조수필
* 공성언
* 김건
* 오주민

## Topics
세마나 주제는 초반 Hot Keyword 개념 스터디, 후반 논문 스터디

### Convolutional NN
* Residual

### Recurrent NN
* Recursive NN
* seq2seq
* LSTM: Long-Short Term Memory
* GRU: Gated Recurrent Units
* Neural Turing Machine

### Generative model
* GAN: Generative Adversarial Networks
* VAE: Variational Auto Encoder

### Reinforcement Learning
* Q-Learning
* DQN(Atari; DeepMind)
* A3C(Asynchronous Advantage Actor-Critic)

### Embedding
* Word2Vec
* Distributed Embedding
* Character Embedding in NLP

### Training Technique
* Attention
* Batch Normalization
* Dropout

### Optimizer
* adam
* rmsprop
* adagrad
* adadelta

### Loss function
* CrossEntropy
* KL divergence

### Model
* Alex Net
* VGG Net
* Res Net
* Inception

### Application: NLP
* Named Entity Recognition
* Embedding
* Neural Machine Translation
* Question Answering
* Sentiment Classification

### Application: Image
* None

## 발표(강의) 구성
* **What**: 해당 개념이 무엇인가?
* **How**: tensorflow기반 tutorial (Code Level 정리)
* **Why**: 왜 해당 개념을 사용해야(배워야) 하는가?
     무슨 의미가 있으며, 이전에 비해 어떤 점이 좋길래.
* **Application**: 도대체 어디에 써먹는가?
* **Reference**